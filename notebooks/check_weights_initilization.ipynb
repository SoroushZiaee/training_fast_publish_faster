{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77864a16-3100-4365-8ed2-472e174241a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b24b59c7-dfaf-4160-9f7c-f4c280a6d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b18829c1-3545-46bc-a8e8-9c634facdd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not same...\n"
     ]
    }
   ],
   "source": [
    "# Assuming model is your PyTorch model\n",
    "\n",
    "class BlurPoolConv2d(torch.nn.Module):\n",
    "\n",
    "    # Purpose: This class creates a convolutional layer that first applies a blurring filter to the input before performing the convolution operation.\n",
    "    # Condition: The function apply_blurpool iterates over all layers of the model and replaces convolution layers (ch.nn.Conv2d) with BlurPoolConv2d if they have a stride greater than 1 and at least 16 input channels.\n",
    "    # Preventing Aliasing: Blurring the output of convolution layers (especially those with strides greater than 1) helps to reduce aliasing effects. Aliasing occurs when high-frequency signals are sampled too sparsely, leading to incorrect representations.\n",
    "    # Smooth Transitions: Applying a blur before downsampling ensures that transitions between pixels are smooth, preserving important information in the feature maps.\n",
    "    # Stabilizing Training: Blurring can help stabilize training by reducing high-frequency noise, making the model less sensitive to small changes in the input data.\n",
    "    def __init__(self, conv):\n",
    "        super().__init__()\n",
    "        default_filter = torch.tensor([[[[1, 2, 1], [2, 4, 2], [1, 2, 1]]]]) / 16.0\n",
    "        filt = default_filter.repeat(conv.in_channels, 1, 1, 1)\n",
    "        self.conv = conv\n",
    "        self.register_buffer(\"blur_filter\", filt)\n",
    "\n",
    "    def forward(self, x):\n",
    "        blurred = F.conv2d(\n",
    "            x,\n",
    "            self.blur_filter,\n",
    "            stride=1,\n",
    "            padding=(1, 1),\n",
    "            groups=self.conv.in_channels,\n",
    "            bias=None,\n",
    "        )\n",
    "        return self.conv.forward(blurred)\n",
    "\n",
    "def apply_blurpool(mod: torch.nn.Module):\n",
    "    for name, child in mod.named_children():\n",
    "        if isinstance(child, torch.nn.Conv2d) and (\n",
    "            np.max(child.stride) > 1 and child.in_channels >= 16\n",
    "        ):\n",
    "            setattr(mod, name, BlurPoolConv2d(child))\n",
    "        else:\n",
    "            apply_blurpool(child)\n",
    "\n",
    "\n",
    "\n",
    "def _load_checkpoint(model, checkpoint_path: str):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n",
    "    checkpoint = checkpoint[\"model_state_dict\"]\n",
    "\n",
    "    new_state_dict = {}\n",
    "    for key, value in checkpoint.items():\n",
    "        if key.startswith(\"module.\"):\n",
    "            new_state_dict[key.replace(\"module.\", \"\")] = value\n",
    "\n",
    "    model.load_state_dict(new_state_dict)\n",
    "\n",
    "\n",
    "use_blurpool = True\n",
    "resnet = resnet50(weights=None)\n",
    "if use_blurpool:\n",
    "    apply_blurpool(resnet)\n",
    "\n",
    "initial_params = [param.clone() for param in resnet.parameters()]\n",
    "\n",
    "_load_checkpoint(resnet, checkpoint_path)\n",
    "\n",
    "for initial, loaded in zip(initial_params, resnet.parameters()):\n",
    "    if not torch.equal(initial, loaded):\n",
    "        print(\"Not same...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c22a464-8e5a-4575-a979-fe46d54e7f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:40<00:00,  2.46it/s]\n"
     ]
    }
   ],
   "source": [
    "def check_initial_weights():\n",
    "    model1 = resnet50(weights=None)\n",
    "    model2 = resnet50(weights=None)\n",
    "\n",
    "    for w1, w2 in zip(model1.parameters(), model2.parameters()):\n",
    "        if not torch.equal(w1, w2):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "counter = 0\n",
    "for _ in tqdm(range(100)):\n",
    "    if check_initial_weights():\n",
    "        counter += 1\n",
    "\n",
    "assert counter==100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a7cb774-4204-4c6e-9b41-46c531e7d6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
