{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import models\n",
    "from torchvision.models.feature_extraction import (\n",
    "    create_feature_extractor,\n",
    "    get_graph_node_names,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuriDataset(Dataset):\n",
    "    def __init__(self, root: str, transforms=None):\n",
    "\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        img_path_list = os.listdir(root)\n",
    "        img_path_list.sort()\n",
    "\n",
    "        self.img_path_list = img_path_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root, self.img_path_list[idx])\n",
    "        # print(f\"{img_name = }\")\n",
    "        image = PIL.Image.open(img_name).convert(\"RGB\")\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "class BlurPoolConv2d(torch.nn.Module):\n",
    "\n",
    "    # Purpose: This class creates a convolutional layer that first applies a blurring filter to the input before performing the convolution operation.\n",
    "    # Condition: The function apply_blurpool iterates over all layers of the model and replaces convolution layers (ch.nn.Conv2d) with BlurPoolConv2d if they have a stride greater than 1 and at least 16 input channels.\n",
    "    # Preventing Aliasing: Blurring the output of convolution layers (especially those with strides greater than 1) helps to reduce aliasing effects. Aliasing occurs when high-frequency signals are sampled too sparsely, leading to incorrect representations.\n",
    "    # Smooth Transitions: Applying a blur before downsampling ensures that transitions between pixels are smooth, preserving important information in the feature maps.\n",
    "    # Stabilizing Training: Blurring can help stabilize training by reducing high-frequency noise, making the model less sensitive to small changes in the input data.\n",
    "    def __init__(self, conv):\n",
    "        super().__init__()\n",
    "        default_filter = torch.tensor([[[[1, 2, 1], [2, 4, 2], [1, 2, 1]]]]) / 16.0\n",
    "        filt = default_filter.repeat(conv.in_channels, 1, 1, 1)\n",
    "        self.conv = conv\n",
    "        self.register_buffer(\"blur_filter\", filt)\n",
    "\n",
    "    def forward(self, x):\n",
    "        blurred = F.conv2d(\n",
    "            x,\n",
    "            self.blur_filter,\n",
    "            stride=1,\n",
    "            padding=(1, 1),\n",
    "            groups=self.conv.in_channels,\n",
    "            bias=None,\n",
    "        )\n",
    "        return self.conv.forward(blurred)\n",
    "        \n",
    "def apply_blurpool(mod: torch.nn.Module):\n",
    "    for name, child in mod.named_children():\n",
    "        if isinstance(child, torch.nn.Conv2d) and (\n",
    "            np.max(child.stride) > 1 and child.in_channels >= 16\n",
    "        ):\n",
    "            setattr(mod, name, BlurPoolConv2d(child))\n",
    "        else:\n",
    "            apply_blurpool(child)\n",
    "\n",
    "def remove_prefix(state_dict, prefix):\n",
    "    \"\"\"\n",
    "    Remove a prefix from the state_dict keys.\n",
    "\n",
    "    Args:\n",
    "    state_dict (dict): State dictionary from which the prefix will be removed.\n",
    "    prefix (str): Prefix to be removed.\n",
    "\n",
    "    Returns:\n",
    "    dict: State dictionary with prefix removed from keys.\n",
    "    \"\"\"\n",
    "    return {key[len(prefix):]: value for key, value in state_dict.items() if key.startswith(prefix)}\n",
    "\n",
    "def match_and_load_weights(checkpoint_state_dict, model, prefix='module.'):\n",
    "    \"\"\"\n",
    "    Match weights from checkpoint_state_dict with model's state_dict and load them into the model.\n",
    "\n",
    "    Args:\n",
    "    checkpoint_state_dict (dict): State dictionary from checkpoint.\n",
    "    model (torch.nn.Module): The model instance.\n",
    "    prefix (str): Prefix to be removed from checkpoint keys.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Remove the prefix from checkpoint state dict keys\n",
    "    cleaned_checkpoint_state_dict = remove_prefix(checkpoint_state_dict, prefix)\n",
    "    \n",
    "    model_state_dict = model.state_dict()\n",
    "    matched_weights = {}\n",
    "\n",
    "    # Iterate over the cleaned checkpoint state dict\n",
    "    for ckpt_key, ckpt_weight in cleaned_checkpoint_state_dict.items():\n",
    "        if ckpt_key in model_state_dict:\n",
    "            # If the layer name matches, add to the matched_weights dict\n",
    "            matched_weights[ckpt_key] = ckpt_weight\n",
    "        else:\n",
    "            print(f\"Layer {ckpt_key} from checkpoint not found in the model state dict.\")\n",
    "    \n",
    "    return matched_weights\n",
    "\n",
    "def get_dataset(root: str, input_size: int = 256):\n",
    "    \n",
    "    normalize = transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    imagenet_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return MuriDataset(root=root, transforms=imagenet_transform)\n",
    "\n",
    "\n",
    "def get_prefix(task: str = \"imagenet\"):\n",
    "    if task == \"imagenet\":\n",
    "        return \"module.\"\n",
    "\n",
    "    elif task == \"memory\":\n",
    "        return \"model.model.\"\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "def get_model(model_name, checkpoint_path: str = None, layer_name: str = None, use_blurpool: bool = True, task: str = \"imagenet\"):\n",
    "    \"\"\"\n",
    "    Create a model from torchvision.models and load weights from checkpoint if provided.\n",
    "\n",
    "    Args:\n",
    "    model_name (str): Name of the model to be created.\n",
    "    checkpoint_path (str): Path to the checkpoint file.\n",
    "    layer_name (str): Name of the layer to extract features from.\n",
    "    use_blurpool (bool): Whether to use BlurPoolConv2d for convolution layers with stride > 1.\n",
    "    task (str): Whether to be imagenet, memory, or combine\n",
    "    \n",
    "\n",
    "    Returns:\n",
    "    torch.nn.Module: The model instance.\n",
    "    \"\"\"\n",
    "    model = getattr(models, model_name)(pretrained=False)\n",
    "    \n",
    "    if use_blurpool:\n",
    "        apply_blurpool(model)\n",
    "    \n",
    "    if checkpoint_path:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        prefix = get_prefix(task)\n",
    "        matched_weights = match_and_load_weights(checkpoint, model, prefix=prefix)\n",
    "        model.load_state_dict(matched_weights)\n",
    "    \n",
    "    if layer_name:\n",
    "        model = create_feature_extractor(model, [layer_name])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runnning this script will extract features from the specified layer of the model for the images in the dataset.\n",
    "# Please specify the root path of the dataset\n",
    "# Please specify the model name\n",
    "# Please specify the path of the checkpoint\n",
    "# Please specify the layer name\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "root = ''' Please specify the path of the dataset here '''\n",
    "ds = get_dataset(root)\n",
    "\n",
    "\n",
    "model_name = ''' Please specify the model name here ''' # example: resnet50\n",
    "checkpoint_path = ''' Please specify the path of the checkpoint here ''' \n",
    "layer_name = ''' Please specify the layer name here '''\n",
    "task = \"memory\" # it could be memory, imagenet, or combine\n",
    "\n",
    "model = get_model(model_name, checkpoint_path, layer_name, task)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "outputs = []\n",
    "for i in tqdm(range(len(ds))):\n",
    "    x = ds[i]\n",
    "    x = x.unsqueeze_(0)\n",
    "    x = x.to(device)\n",
    "    output = model(x)\n",
    "    if device == \"cpu\":\n",
    "        output = output['it'].flatten(start_dim=0).detach().numpy().reshape(1, -1)\n",
    "    else:\n",
    "        output = output['it'].flatten(start_dim=0).detach().cpu().numpy().reshape(1, -1)\n",
    "    outputs.append(output)\n",
    "\n",
    "outputs = np.concatenate(outputs, axis=0) # Shape should be (1320, outout_dim_of_it)\n",
    "print(f\"{outputs.shape = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Code\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "root = \"/home/soroush1/projects/def-kohitij/soroush1/training_fast_publish_faster/data/muri1320\"\n",
    "ds = get_dataset(root)\n",
    "\n",
    "\n",
    "model_name = \"resnet50\" # example: resnet50\n",
    "checkpoint_path = \"/home/soroush1/projects/def-kohitij/soroush1/training_fast_publish_faster/resnet50_logs/resnet50-0/final_weights.pt\"\n",
    "layer_name = \"layer3.2.bn1\"\n",
    "task = \"imagenet\" # it could be memory, imagenet, or combine\n",
    "\n",
    "model = get_model(model_name, checkpoint_path, layer_name, task)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "outputs = []\n",
    "for i in tqdm(range(len(ds))):\n",
    "    x = ds[i]\n",
    "    x = x.unsqueeze_(0)\n",
    "    x = x.to(device)\n",
    "    output = model(x)\n",
    "    if device == \"cpu\":\n",
    "        output = output['it'].flatten(start_dim=0).detach().numpy().reshape(1, -1)\n",
    "    else:\n",
    "        output = output['it'].flatten(start_dim=0).detach().cpu().numpy().reshape(1, -1)\n",
    "    outputs.append(output)\n",
    "\n",
    "outputs = np.concatenate(outputs, axis=0)\n",
    "print(f\"{outputs.shape = }\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudocode Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1320/1320 [00:07<00:00, 176.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs.shape = (1320, 65536)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"resnet50\"\n",
    "checkpoint_path = \"/home/soroush1/projects/def-kohitij/soroush1/training_fast_publish_faster/weights/resnet50-1/checkpoint_epoch_90_0.77.pth\"\n",
    "layer_name = \"layer3.2.bn1\"\n",
    "use_blurpool = True\n",
    "\n",
    "model = getattr(models, model_name)(weights=None)\n",
    "\n",
    "if use_blurpool:\n",
    "    apply_blurpool(model)\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "    \n",
    "checkpoint_state_dict = torch.load(checkpoint_path, map_location=device)\n",
    "checkpoint_state_dict = checkpoint_state_dict[\"model_state_dict\"]\n",
    "\n",
    "update_state_dict = match_and_load_weights(checkpoint_state_dict, model)\n",
    "model.load_state_dict(update_state_dict)\n",
    "\n",
    "model = create_feature_extractor(model, return_nodes={layer_name: \"it\"})\n",
    "model.eval()\n",
    "\n",
    "outputs = []\n",
    "for i in tqdm(range(len(ds))):\n",
    "    x = ds[i]\n",
    "    x = x.unsqueeze_(0)\n",
    "    x = x.to(device)\n",
    "    output = model(x)\n",
    "    if device == \"cpu\":\n",
    "        output = output['it'].flatten(start_dim=0).detach().numpy().reshape(1, -1)\n",
    "    else:\n",
    "        output = output['it'].flatten(start_dim=0).detach().cpu().numpy().reshape(1, -1)\n",
    "    outputs.append(output)\n",
    "\n",
    "outputs = np.concatenate(outputs, axis=0)\n",
    "print(f\"{outputs.shape = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0114, -0.0323,  0.0010,  0.0307, -0.0376,  0.0025, -0.0234, -0.0277,\n",
       "         0.0225,  0.0516], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()[\"conv1.weight\"][:10, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_136376/249214711.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcheckpoint_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcheckpoint_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_state_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mupdate_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_and_load_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_state_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.model.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'state_dict'"
     ]
    }
   ],
   "source": [
    "model_name = \"resnet50\"\n",
    "checkpoint_path = \"/home/soroush1/projects/def-kohitij/soroush1/training_fast_publish_faster/vgg19_weights/vgg19-0/checkpoint_epoch_90_0.63.pth\"\n",
    "layer_name = \"layer3.2.bn1\"\n",
    "use_blurpool = True\n",
    "\n",
    "model = getattr(models, model_name)(weights=None)\n",
    "\n",
    "if use_blurpool:\n",
    "    apply_blurpool(model)\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "    \n",
    "checkpoint_state_dict = torch.load(checkpoint_path, map_location=device)\n",
    "checkpoint_state_dict = checkpoint_state_dict[\"state_dict\"]\n",
    "\n",
    "update_state_dict = match_and_load_weights(checkpoint_state_dict, model, prefix='model.model.')\n",
    "model.load_state_dict(update_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
