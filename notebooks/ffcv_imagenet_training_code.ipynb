{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132cdb17-66ac-4d17-a37a-6bc5e9cefe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b7bc15-1de0-4dc1-b0d6-41802fc8d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c82c1e-1576-4b43-8f35-0841bf592992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as ch\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.cuda.amp import autocast\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "\n",
    "ch.backends.cudnn.benchmark = True\n",
    "ch.autograd.profiler.emit_nvtx(False)\n",
    "ch.autograd.profiler.profile(False)\n",
    "\n",
    "from torchvision import models\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from uuid import uuid4\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from fastargs import get_current_config\n",
    "from fastargs.decorators import param\n",
    "from fastargs import Param, Section\n",
    "from fastargs.validation import And, OneOf\n",
    "\n",
    "from ffcv.pipeline.operation import Operation\n",
    "from ffcv.loader import Loader, OrderOption\n",
    "from ffcv.transforms import (\n",
    "    ToTensor,\n",
    "    ToDevice,\n",
    "    Squeeze,\n",
    "    NormalizeImage,\n",
    "    RandomHorizontalFlip,\n",
    "    ToTorchImage,\n",
    ")\n",
    "from ffcv.fields.rgb_image import (\n",
    "    CenterCropRGBImageDecoder,\n",
    "    RandomResizedCropRGBImageDecoder,\n",
    ")\n",
    "from ffcv.fields.basics import IntDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4559e6ab-dd4c-48f7-8198-432cd5c483ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlurPoolConv2d(ch.nn.Module):\n",
    "\n",
    "    # Purpose: This class creates a convolutional layer that first applies a blurring filter to the input before performing the convolution operation.\n",
    "    # Condition: The function apply_blurpool iterates over all layers of the model and replaces convolution layers (ch.nn.Conv2d) with BlurPoolConv2d if they have a stride greater than 1 and at least 16 input channels.\n",
    "    # Preventing Aliasing: Blurring the output of convolution layers (especially those with strides greater than 1) helps to reduce aliasing effects. Aliasing occurs when high-frequency signals are sampled too sparsely, leading to incorrect representations.\n",
    "    # Smooth Transitions: Applying a blur before downsampling ensures that transitions between pixels are smooth, preserving important information in the feature maps.\n",
    "    # Stabilizing Training: Blurring can help stabilize training by reducing high-frequency noise, making the model less sensitive to small changes in the input data.\n",
    "    def __init__(self, conv):\n",
    "        super().__init__()\n",
    "        default_filter = ch.tensor([[[[1, 2, 1], [2, 4, 2], [1, 2, 1]]]]) / 16.0\n",
    "        filt = default_filter.repeat(conv.in_channels, 1, 1, 1)\n",
    "        self.conv = conv\n",
    "        self.register_buffer(\"blur_filter\", filt)\n",
    "\n",
    "    def forward(self, x):\n",
    "        blurred = F.conv2d(\n",
    "            x,\n",
    "            self.blur_filter,\n",
    "            stride=1,\n",
    "            padding=(1, 1),\n",
    "            groups=self.conv.in_channels,\n",
    "            bias=None,\n",
    "        )\n",
    "        return self.conv.forward(blurred)\n",
    "\n",
    "\n",
    "class MeanScalarMetric(torchmetrics.Metric):\n",
    "    # Necessity: Ensures that the mean calculation works correctly in a distributed training setup, where metrics need to be aggregated across multiple devices.\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.add_state(\"sum\", default=ch.tensor(0.0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"count\", default=ch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, sample: ch.Tensor):\n",
    "        self.sum += sample.sum()\n",
    "        self.count += sample.numel()\n",
    "\n",
    "    def compute(self):\n",
    "        return self.sum.float() / self.count\n",
    "\n",
    "\n",
    "def get_step_lr(epoch, lr, step_ratio, step_length, epochs):\n",
    "    if epoch >= epochs:\n",
    "        return 0\n",
    "\n",
    "    num_steps = epoch // step_length\n",
    "    return step_ratio**num_steps * lr\n",
    "\n",
    "\n",
    "def get_cyclic_lr(epoch, lr, epochs, lr_peak_epoch):\n",
    "    xs = [0, lr_peak_epoch, epochs]\n",
    "    ys = [1e-4 * lr, lr, 0]\n",
    "    return np.interp([epoch], xs, ys)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e5fb15-404a-42fe-a3bc-245e5b3e66fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = np.array([0.485, 0.456, 0.406]) * 255\n",
    "IMAGENET_STD = np.array([0.229, 0.224, 0.225]) * 255\n",
    "DEFAULT_CROP_RATIO = 224 / 256\n",
    "\n",
    "\n",
    "class ImageNetTrainer:\n",
    "    def __init__(self, gpu, config, verbose: bool = True):\n",
    "        self.gpu = gpu\n",
    "        self.config = config\n",
    "        self.uid = str(uuid4())\n",
    "\n",
    "        if self.config[\"distributed\"]:\n",
    "            self.setup_distributed()\n",
    "\n",
    "        if verbose:\n",
    "            print(\"loading dataset...\")\n",
    "        self.train_loader = self.create_train_loader()\n",
    "        self.val_loader = self.create_val_loader()\n",
    "\n",
    "        if verbose:\n",
    "            print(\"loading model and optimizers...\")\n",
    "        self.model, self.scaler = self.create_model_and_scaler()\n",
    "        self.create_optimizer()\n",
    "\n",
    "        if verbose:\n",
    "            print(\"init loggers...\")\n",
    "        self.initialize_logger()\n",
    "\n",
    "    def setup_distributed(self):\n",
    "        os.environ[\"MASTER_ADDR\"] = self.config[\"address\"]\n",
    "        os.environ[\"MASTER_PORT\"] = self.config[\"port\"]\n",
    "\n",
    "        dist.init_process_group(\n",
    "            \"nccl\", rank=self.gpu, world_size=self.config[\"world_size\"]\n",
    "        )\n",
    "        ch.cuda.set_device(self.gpu)\n",
    "\n",
    "    def cleanup_distributed(self):\n",
    "        dist.destroy_process_group()\n",
    "\n",
    "    def get_lr(self, epoch):\n",
    "        lr_schedules = {\"cyclic\": get_cyclic_lr, \"step\": get_step_lr}\n",
    "        return lr_schedules[self.config[\"lr_schedule_type\"]](\n",
    "            epoch,\n",
    "            lr=self.config[\"lr\"],\n",
    "            epochs=self.config[\"epochs\"],\n",
    "            lr_peak_epoch=self.config[\"lr_peak_epoch\"],\n",
    "        )\n",
    "\n",
    "    def get_resolution(self, epoch):\n",
    "        min_res = self.config[\"min_res\"]\n",
    "        max_res = self.config[\"max_res\"]\n",
    "        end_ramp = self.config[\"end_ramp\"]\n",
    "        start_ramp = self.config[\"start_ramp\"]\n",
    "\n",
    "        assert min_res <= max_res\n",
    "\n",
    "        if epoch <= start_ramp:\n",
    "            return min_res\n",
    "\n",
    "        if epoch >= end_ramp:\n",
    "            return max_res\n",
    "\n",
    "        interp = np.interp([epoch], [start_ramp, end_ramp], [min_res, max_res])\n",
    "        final_res = int(np.round(interp[0] / 32)) * 32\n",
    "        return final_res\n",
    "\n",
    "    def create_optimizer(self):\n",
    "        momentum = self.config[\"momentum\"]\n",
    "        optimizer = self.config[\"optimizer\"]\n",
    "        weight_decay = self.config[\"weight_decay\"]\n",
    "        label_smoothing = self.config[\"label_smoothing\"]\n",
    "\n",
    "        assert optimizer == \"sgd\"\n",
    "\n",
    "        all_params = list(self.model.named_parameters())\n",
    "        bn_params = [v for k, v in all_params if (\"bn\" in k)]\n",
    "        other_params = [v for k, v in all_params if not (\"bn\" in k)]\n",
    "        param_groups = [\n",
    "            {\"params\": bn_params, \"weight_decay\": 0.0},\n",
    "            {\"params\": other_params, \"weight_decay\": weight_decay},\n",
    "        ]\n",
    "\n",
    "        self.optimizer = ch.optim.SGD(param_groups, lr=1, momentum=momentum)\n",
    "        self.loss = ch.nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "    def create_train_loader(self):\n",
    "        train_dataset = self.config[\"train_dataset\"]\n",
    "        num_workers = self.config[\"num_workers\"]\n",
    "        batch_size = self.config[\"train_batch_size\"]\n",
    "        distributed = self.config[\"distributed\"]\n",
    "        in_memory = self.config[\"in_memory\"]\n",
    "\n",
    "        this_device = f\"cuda:{self.gpu}\"\n",
    "        train_path = Path(train_dataset)\n",
    "        assert train_path.is_file()\n",
    "\n",
    "        res = self.get_resolution(epoch=0)\n",
    "        self.decoder = RandomResizedCropRGBImageDecoder((res, res))\n",
    "        image_pipeline = [\n",
    "            self.decoder,\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(),\n",
    "            ToDevice(ch.device(this_device), non_blocking=True),\n",
    "            ToTorchImage(),\n",
    "            NormalizeImage(IMAGENET_MEAN, IMAGENET_STD, np.float16),\n",
    "        ]\n",
    "\n",
    "        label_pipeline = [\n",
    "            IntDecoder(),\n",
    "            ToTensor(),\n",
    "            Squeeze(),\n",
    "            ToDevice(ch.device(this_device), non_blocking=True),\n",
    "        ]\n",
    "\n",
    "        order = OrderOption.RANDOM if distributed else OrderOption.QUASI_RANDOM\n",
    "        loader = Loader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers,\n",
    "            order=order,\n",
    "            os_cache=in_memory,\n",
    "            drop_last=True,\n",
    "            pipelines={\"image\": image_pipeline, \"label\": label_pipeline},\n",
    "            distributed=distributed,\n",
    "        )\n",
    "\n",
    "        return loader\n",
    "\n",
    "    def create_val_loader(self):\n",
    "        val_dataset = self.config[\"val_dataset\"]\n",
    "        num_workers = self.config[\"num_workers\"]\n",
    "        batch_size = self.config[\"val_batch_size\"]\n",
    "        resolution = self.config[\"resolution\"]\n",
    "        distributed = self.config[\"distributed\"]\n",
    "\n",
    "        this_device = f\"cuda:{self.gpu}\"\n",
    "        val_path = Path(val_dataset)\n",
    "        assert val_path.is_file()\n",
    "        res_tuple = (resolution, resolution)\n",
    "        cropper = CenterCropRGBImageDecoder(res_tuple, ratio=DEFAULT_CROP_RATIO)\n",
    "        image_pipeline = [\n",
    "            cropper,\n",
    "            ToTensor(),\n",
    "            ToDevice(ch.device(this_device), non_blocking=True),\n",
    "            ToTorchImage(),\n",
    "            NormalizeImage(IMAGENET_MEAN, IMAGENET_STD, np.float16),\n",
    "        ]\n",
    "\n",
    "        label_pipeline = [\n",
    "            IntDecoder(),\n",
    "            ToTensor(),\n",
    "            Squeeze(),\n",
    "            ToDevice(ch.device(this_device), non_blocking=True),\n",
    "        ]\n",
    "\n",
    "        loader = Loader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers,\n",
    "            order=OrderOption.SEQUENTIAL,\n",
    "            drop_last=False,\n",
    "            pipelines={\"image\": image_pipeline, \"label\": label_pipeline},\n",
    "            distributed=distributed,\n",
    "        )\n",
    "        return loader\n",
    "\n",
    "    def train(self):\n",
    "        epochs = self.config[\"epochs\"]\n",
    "        log_level = self.config[\"log_level\"]\n",
    "        for epoch in range(epochs):\n",
    "            res = self.get_resolution(epoch)\n",
    "            self.decoder.output_size = (res, res)\n",
    "            train_loss = self.train_loop(epoch)\n",
    "\n",
    "            if log_level > 0:\n",
    "                extra_dict = {\"train_loss\": train_loss, \"epoch\": epoch}\n",
    "                self.eval_and_log(extra_dict)\n",
    "\n",
    "        self.eval_and_log({\"epoch\": epoch})\n",
    "        if self.gpu == 0:\n",
    "            ch.save(self.model.state_dict(), self.log_folder / \"final_weights.pt\")\n",
    "\n",
    "    def eval_and_log(self, extra_dict={}):\n",
    "        start_val = time.time()\n",
    "        stats = self.val_loop()\n",
    "        val_time = time.time() - start_val\n",
    "        if self.gpu == 0:\n",
    "            self.log(\n",
    "                dict(\n",
    "                    {\n",
    "                        \"current_lr\": self.optimizer.param_groups[0][\"lr\"],\n",
    "                        \"top_1\": stats[\"top_1\"],\n",
    "                        \"top_5\": stats[\"top_5\"],\n",
    "                        \"val_time\": val_time,\n",
    "                    },\n",
    "                    **extra_dict,\n",
    "                )\n",
    "            )\n",
    "        return stats\n",
    "\n",
    "    def create_model_and_scaler(self):\n",
    "        scaler = GradScaler()\n",
    "        arch = self.config[\"arch\"]\n",
    "        weights = self.config[\"weights\"]\n",
    "        use_blurpool = self.config[\"use_blurpool\"]\n",
    "\n",
    "        model = getattr(models, arch)(weights=weights)\n",
    "\n",
    "        def apply_blurpool(mod: ch.nn.Module):\n",
    "            for name, child in mod.named_children():\n",
    "                if isinstance(child, ch.nn.Conv2d) and (\n",
    "                    np.max(child.stride) > 1 and child.in_channels >= 16\n",
    "                ):\n",
    "                    setattr(mod, name, BlurPoolConv2d(child))\n",
    "                else:\n",
    "                    apply_blurpool(child)\n",
    "\n",
    "        if use_blurpool:\n",
    "            apply_blurpool(model)\n",
    "\n",
    "        model = model.to(memory_format=ch.channels_last)\n",
    "        model = model.to(self.gpu)\n",
    "\n",
    "        if self.config[\"distributed\"]:\n",
    "            model = ch.nn.parallel.DistributedDataParallel(model, device_ids=[self.gpu])\n",
    "\n",
    "        return model, scaler\n",
    "\n",
    "    def train_loop(self, epoch):\n",
    "        model = self.model\n",
    "        model.train()\n",
    "        losses = []\n",
    "\n",
    "        lr_start, lr_end = self.get_lr(epoch), self.get_lr(epoch + 1)\n",
    "        iters = len(self.train_loader)\n",
    "        lrs = np.interp(np.arange(iters), [0, iters], [lr_start, lr_end])\n",
    "\n",
    "        iterator = tqdm(self.train_loader)\n",
    "        for ix, (images, target) in enumerate(iterator):\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group[\"lr\"] = lrs[ix]\n",
    "\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            with autocast():\n",
    "                output = self.model(images)\n",
    "                loss_train = self.loss(output, target)\n",
    "\n",
    "            self.scaler.scale(loss_train).backward()\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "\n",
    "            if self.config[\"log_level\"] > 0:\n",
    "                losses.append(loss_train.detach())\n",
    "\n",
    "                group_lrs = []\n",
    "                for _, group in enumerate(self.optimizer.param_groups):\n",
    "                    group_lrs.append(f'{group[\"lr\"]:.3f}')\n",
    "\n",
    "                names = [\"ep\", \"iter\", \"shape\", \"lrs\"]\n",
    "                values = [epoch, ix, tuple(images.shape), group_lrs]\n",
    "                if self.config[\"log_level\"] > 1:\n",
    "                    names += [\"loss\"]\n",
    "                    values += [f\"{loss_train.item():.3f}\"]\n",
    "\n",
    "                msg = \", \".join(f\"{n}={v}\" for n, v in zip(names, values))\n",
    "                iterator.set_description(msg)\n",
    "\n",
    "    def val_loop(self):\n",
    "        model = self.model\n",
    "        model.eval()\n",
    "        with ch.no_grad():\n",
    "            with autocast():\n",
    "                for images, target in tqdm(self.val_loader):\n",
    "                    output = self.model(images)\n",
    "                    if self.config[\"lr_tta\"]:\n",
    "                        output += self.model(ch.flip(images, dims=[3]))\n",
    "\n",
    "                    for k in [\"top_1\", \"top_5\"]:\n",
    "                        self.val_meters[k](output, target)\n",
    "\n",
    "                    loss_val = self.loss(output, target)\n",
    "                    self.val_meters[\"loss\"](loss_val)\n",
    "\n",
    "        stats = {k: m.compute().item() for k, m in self.val_meters.items()}\n",
    "        [meter.reset() for meter in self.val_meters.values()]\n",
    "        return stats\n",
    "\n",
    "    def initialize_logger(self):\n",
    "        self.val_meters = {\n",
    "            \"top_1\": torchmetrics.Accuracy(task=\"multiclass\", num_classes=1000).to(\n",
    "                self.gpu\n",
    "            ),\n",
    "            \"top_5\": torchmetrics.Accuracy(\n",
    "                task=\"multiclass\",\n",
    "                num_classes=1000,\n",
    "                top_k=5,\n",
    "            ).to(self.gpu),\n",
    "            \"loss\": MeanScalarMetric().to(self.gpu),\n",
    "        }\n",
    "\n",
    "        if self.gpu == 0:\n",
    "            folder = (Path(self.config[\"folder\"]) / str(self.uid)).absolute()\n",
    "            folder.mkdir(parents=True)\n",
    "            self.log_folder = folder\n",
    "            self.start_time = time.time()\n",
    "            print(f\"=> Logging in {self.log_folder}\")\n",
    "            params = self.config\n",
    "            with open(folder / \"params.json\", \"w+\") as handle:\n",
    "                json.dump(params, handle)\n",
    "\n",
    "    def log(self, content):\n",
    "        print(f\"=> Log: {content}\")\n",
    "        if self.gpu != 0:\n",
    "            return\n",
    "        cur_time = time.time()\n",
    "        with open(self.log_folder / \"log\", \"a+\") as fd:\n",
    "            fd.write(\n",
    "                json.dumps(\n",
    "                    {\n",
    "                        \"timestamp\": cur_time,\n",
    "                        \"relative_time\": cur_time - self.start_time,\n",
    "                        **content,\n",
    "                    }\n",
    "                )\n",
    "                + \"\\n\"\n",
    "            )\n",
    "            fd.flush()\n",
    "\n",
    "    @classmethod\n",
    "    def launch(cls, config):\n",
    "        if config[\"distributed\"]:\n",
    "            ch.multiprocessing.spawn(\n",
    "                cls._exec_wrapper,\n",
    "                nprocs=config[\"world_size\"],\n",
    "                join=True,\n",
    "                args=(config,),\n",
    "            )\n",
    "        else:\n",
    "            cls.exec(0, config)\n",
    "\n",
    "    @classmethod\n",
    "    def _exec_wrapper(cls, gpu, config):\n",
    "        cls.exec(gpu, config)\n",
    "\n",
    "    @classmethod\n",
    "    def exec(cls, gpu, config):\n",
    "        trainer = cls(gpu=gpu, config=config)\n",
    "        if config[\"eval_only\"]:\n",
    "            trainer.eval_and_log()\n",
    "        else:\n",
    "            trainer.train()\n",
    "\n",
    "        if config[\"distributed\"]:\n",
    "            trainer.cleanup_distributed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f4725-9325-4062-b2ee-520837ed72ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        \"arch\": \"resnet50\",\n",
    "        \"weights\": None,\n",
    "        \"min_res\": 160,\n",
    "        \"max_res\": 192,\n",
    "        \"end_ramp\": 76,\n",
    "        \"start_ramp\": 65,\n",
    "        \"train_dataset\": \"/home/soroush1/projects/def-kohitij/soroush1/training_fast_publish_faster/data/imagenet_train_256.ffcv\",\n",
    "        \"val_dataset\": \"/home/soroush1/projects/def-kohitij/soroush1/training_fast_publish_faster/data/imagenet_validation_256.ffcv\",\n",
    "        \"num_workers\": 10,\n",
    "        \"in_memory\": 1,\n",
    "        \"step_ratio\": 0.1,\n",
    "        \"step_length\": 30,\n",
    "        \"lr_schedule_type\": \"cyclic\",\n",
    "        \"lr\": 1.7,\n",
    "        \"lr_peak_epoch\": 2,\n",
    "        \"folder\": \"./logs\",\n",
    "        \"log_level\": 1,\n",
    "        \"train_batch_size\": 512,\n",
    "        \"val_batch_size\": 512,\n",
    "        \"resolution\": 224,\n",
    "        \"lr_tta\": 1,\n",
    "        \"eval_only\": 0,\n",
    "        \"optimizer\": \"sgd\",\n",
    "        \"momentum\": 0.9,\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"epochs\": 90,\n",
    "        \"label_smoothing\": 0.1,\n",
    "        \"distributed\": 0,\n",
    "        \"use_blurpool\": 1,\n",
    "        \"world_size\": 1,\n",
    "        \"address\": \"localhost\",\n",
    "        \"port\": \"12355\"\n",
    "    }\n",
    "\n",
    "ImageNetTrainer.launch(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
