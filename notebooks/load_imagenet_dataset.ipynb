{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree(\"train/n02096437\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the train folder: 236816\n"
     ]
    }
   ],
   "source": [
    "# Load the ImageNet train dataset\n",
    "train_dir = \"train/\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=None)\n",
    "\n",
    "# Get the number of images in the train dataset\n",
    "num_images = len(train_dataset)\n",
    "\n",
    "print(f\"Number of images in the train folder: {num_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import tarfile\n",
    "\n",
    "\n",
    "def get_uncompressed_size(tar_file_path):\n",
    "    total_uncompressed_size = 0\n",
    "\n",
    "    # Open the tar file\n",
    "    with tarfile.open(tar_file_path, \"r\") as tar_file:\n",
    "        # Iterate over each file in the tar archive\n",
    "        for tar_info in tqdm(tar_file.getmembers()):\n",
    "            # Accumulate the uncompressed size\n",
    "            if tar_info.isfile():  # Ensure it's a file, not a directory or link\n",
    "                total_uncompressed_size += tar_info.size\n",
    "\n",
    "    return total_uncompressed_size\n",
    "\n",
    "\n",
    "# Path to the zip file\n",
    "zip_file_path = (\n",
    "    \"/home/soroush1/projects/def-kohitij/soroush1/imagenet/ILSVRC2012_img_train.tar\"\n",
    ")\n",
    "\n",
    "# Calculate the total uncompressed size\n",
    "uncompressed_size = get_uncompressed_size(zip_file_path)\n",
    "\n",
    "# Convert the size to a more readable format (e.g., GB)\n",
    "uncompressed_size_gb = uncompressed_size / (1024**3)\n",
    "\n",
    "print(f\"Total uncompressed size: {uncompressed_size_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_size_of_tar(tar_file_path):\n",
    "    total_size = 0\n",
    "\n",
    "    def process_tar(tar_file):\n",
    "        nonlocal total_size\n",
    "        for member in tar_file.getmembers():\n",
    "            if member.isfile():\n",
    "                total_size += member.size\n",
    "            if member.isfile() and member.name.endswith(\".tar\"):\n",
    "                with tar_file.extractfile(member) as nested_tar_file_obj:\n",
    "                    nested_tar_file_path = os.path.join(\"/tmp\", member.name)\n",
    "                    with open(nested_tar_file_path, \"wb\") as f:\n",
    "                        f.write(nested_tar_file_obj.read())\n",
    "                    with tarfile.open(nested_tar_file_path, \"r\") as nested_tar_file:\n",
    "                        process_tar(nested_tar_file)\n",
    "                    os.remove(nested_tar_file_path)\n",
    "\n",
    "    # Open the outer tar file\n",
    "    with tarfile.open(tar_file_path, \"r\") as tar_file:\n",
    "        process_tar(tar_file)\n",
    "\n",
    "    return total_size\n",
    "\n",
    "\n",
    "# Path to the tar file\n",
    "tar_file_path = (\n",
    "    \"/home/soroush1/projects/def-kohitij/soroush1/imagenet/ILSVRC2012_img_train.tar\"\n",
    ")\n",
    "\n",
    "# Calculate the total uncompressed size of all files in the tar archive\n",
    "total_size = get_total_size_of_tar(tar_file_path)\n",
    "\n",
    "# Convert the size to a more readable format (e.g., GB)\n",
    "total_size_gb = total_size / (1024**3)\n",
    "\n",
    "print(\n",
    "    f\"Total uncompressed size of all files in the tar archive: {total_size_gb:.2f} GB\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_tar_contents(tar_file_path):\n",
    "    # Open the tar file\n",
    "    with tarfile.open(tar_file_path, \"r\") as tar_file:\n",
    "        # List all the files in the tar archive\n",
    "        tar_file.list()\n",
    "\n",
    "\n",
    "# List the contents of the tar file\n",
    "list_tar_contents(\n",
    "    tar_file_path=\"/home/soroush1/projects/def-kohitij/soroush1/imagenet/ILSVRC2012_img_train.tar\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files_in_tar(tar_file_path):\n",
    "    file_count = 0\n",
    "\n",
    "    # Open the tar file\n",
    "    with tarfile.open(tar_file_path, \"r\") as tar_file:\n",
    "        # Iterate over each member in the tar archive\n",
    "        for tar_info in tar_file.getmembers():\n",
    "            # Increment the count if it's a file\n",
    "            if tar_info.isfile():\n",
    "                file_count += 1\n",
    "\n",
    "    return file_count\n",
    "\n",
    "\n",
    "# List the contents of the tar file\n",
    "count_files_in_tar(\n",
    "    tar_file_path=\"/home/soroush1/projects/def-kohitij/soroush1/imagenet/ILSVRC2012_img_train.tar\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "\n",
    "def extract_tar_files(tar_file_path, extract_dir):\n",
    "    # Create the extraction directory if it doesn't exist\n",
    "    if not os.path.exists(extract_dir):\n",
    "        os.makedirs(extract_dir)\n",
    "\n",
    "    # Open the outer tar file\n",
    "    with tarfile.open(tar_file_path, \"r\") as tar_file:\n",
    "        # Iterate over each member in the tar archive\n",
    "        for i, member in tqdm(enumerate(tar_file.getmembers()), total=1000):\n",
    "            if member.isfile() and member.name.endswith(\".tar\"):\n",
    "                # Create a folder for the nested tar file\n",
    "                folder_name = os.path.join(\n",
    "                    extract_dir, os.path.splitext(member.name)[0]\n",
    "                )\n",
    "\n",
    "                if not os.path.exists(folder_name):\n",
    "                    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "                    # Extract the nested tar file to the folder\n",
    "                    nested_tar_path = os.path.join(folder_name, member.name)\n",
    "                    with tar_file.extractfile(member) as nested_tar_file_obj:\n",
    "                        with open(nested_tar_path, \"wb\") as f:\n",
    "                            f.write(nested_tar_file_obj.read())\n",
    "\n",
    "                    # Extract the contents of the nested tar file\n",
    "                    with tarfile.open(nested_tar_path, \"r\") as nested_tar_file:\n",
    "                        nested_tar_file.extractall(folder_name)\n",
    "\n",
    "                    # Remove the nested tar file after extraction\n",
    "                    os.remove(nested_tar_path)\n",
    "\n",
    "\n",
    "# Path to the main tar file\n",
    "tar_file_path = (\n",
    "    \"/home/soroush1/projects/def-kohitij/soroush1/imagenet/ILSVRC2012_img_train.tar\"\n",
    ")\n",
    "\n",
    "# Directory to extract the contents to\n",
    "extract_dir = \"train\"\n",
    "\n",
    "# Extract the tar files\n",
    "extract_tar_files(tar_file_path, extract_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 30/1000 [00:00<00:08, 117.22it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 122] Disk quota exceeded: '/home/soroush1/nearline/def-kohitij/soroush1/train_folder/n01514859/n01514859_8763.JPEG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/lustre06/project/6067616/soroush1/training_fast_publish_faster/.venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/lustre06/project/6067616/soroush1/training_fast_publish_faster/.venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/lustre06/project/6067616/soroush1/training_fast_publish_faster/.venv/lib/python3.9/site-packages/joblib/parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n  File \"/lustre06/project/6067616/soroush1/training_fast_publish_faster/.venv/lib/python3.9/site-packages/joblib/parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/tmp/ipykernel_1483505/3587364779.py\", line 23, in extract_nested_tar\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.9.6/lib/python3.9/tarfile.py\", line 2036, in extractall\n    self.extract(tarinfo, path, set_attrs=not tarinfo.isdir(),\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.9.6/lib/python3.9/tarfile.py\", line 2077, in extract\n    self._extract_member(tarinfo, os.path.join(path, tarinfo.name),\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.9.6/lib/python3.9/tarfile.py\", line 2150, in _extract_member\n    self.makefile(tarinfo, targetpath)\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.9.6/lib/python3.9/tarfile.py\", line 2191, in makefile\n    with bltn_open(targetpath, \"wb\") as target:\nOSError: [Errno 122] Disk quota exceeded: '/home/soroush1/nearline/def-kohitij/soroush1/train_folder/n01514859/n01514859_8763.JPEG'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Extract the tar files\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[43mextract_tar_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtar_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 44\u001b[0m, in \u001b[0;36mextract_tar_files\u001b[0;34m(tar_file_path, extract_dir, n_jobs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     members \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     34\u001b[0m         member\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m member \u001b[38;5;129;01min\u001b[39;00m tar_file\u001b[38;5;241m.\u001b[39mgetmembers()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m         )\n\u001b[1;32m     41\u001b[0m     ]\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(members))\n\u001b[0;32m---> 44\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_nested_tar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmember\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtar_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmember\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmembers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/lustre06/project/6067616/soroush1/training_fast_publish_faster/.venv/lib/python3.9/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/lustre06/project/6067616/soroush1/training_fast_publish_faster/.venv/lib/python3.9/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/lustre06/project/6067616/soroush1/training_fast_publish_faster/.venv/lib/python3.9/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m/lustre06/project/6067616/soroush1/training_fast_publish_faster/.venv/lib/python3.9/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/lustre06/project/6067616/soroush1/training_fast_publish_faster/.venv/lib/python3.9/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/lustre06/project/6067616/soroush1/training_fast_publish_faster/.venv/lib/python3.9/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 122] Disk quota exceeded: '/home/soroush1/nearline/def-kohitij/soroush1/train_folder/n01514859/n01514859_8763.JPEG'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|▎         | 30/1000 [00:16<00:08, 117.22it/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def extract_nested_tar(nested_tar_info, tar_file_path, extract_dir):\n",
    "    with tarfile.open(tar_file_path, \"r\") as tar_file:\n",
    "        nested_tar_file_obj = tar_file.extractfile(nested_tar_info)\n",
    "        if nested_tar_file_obj is None:\n",
    "            return\n",
    "\n",
    "        folder_name = os.path.join(\n",
    "            extract_dir, os.path.splitext(nested_tar_info.name)[0]\n",
    "        )\n",
    "        os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "        nested_tar_path = os.path.join(folder_name, nested_tar_info.name)\n",
    "        with open(nested_tar_path, \"wb\") as f:\n",
    "            f.write(nested_tar_file_obj.read())\n",
    "\n",
    "        with tarfile.open(nested_tar_path, \"r\") as nested_tar_file:\n",
    "            nested_tar_file.extractall(folder_name)\n",
    "\n",
    "        os.remove(nested_tar_path)\n",
    "\n",
    "\n",
    "def extract_tar_files(tar_file_path, extract_dir, n_jobs=-1):\n",
    "    if not os.path.exists(extract_dir):\n",
    "        os.makedirs(extract_dir)\n",
    "\n",
    "    with tarfile.open(tar_file_path, \"r\") as tar_file:\n",
    "        members = [\n",
    "            member\n",
    "            for member in tar_file.getmembers()\n",
    "            if member.isfile()\n",
    "            and member.name.endswith(\".tar\")\n",
    "            and not os.path.exists(\n",
    "                os.path.join(extract_dir, os.path.splitext(member.name)[0])\n",
    "            )\n",
    "        ]\n",
    "        print(len(members))\n",
    "\n",
    "    Parallel(n_jobs=n_jobs)(\n",
    "        delayed(extract_nested_tar)(member, tar_file_path, extract_dir)\n",
    "        for member in tqdm(members)\n",
    "    )\n",
    "\n",
    "\n",
    "# Path to the main tar file\n",
    "tar_file_path = (\n",
    "    \"/home/soroush1/projects/def-kohitij/soroush1/imagenet/ILSVRC2012_img_train.tar\"\n",
    ")\n",
    "\n",
    "# Directory to extract the contents to\n",
    "extract_dir = \"/home/soroush1/nearline/def-kohitij/soroush1/train_folder\"\n",
    "\n",
    "# Number of parallel jobs (use -1 to use all CPUs, or specify a number)\n",
    "n_jobs = 30\n",
    "\n",
    "# Extract the tar files\n",
    "extract_tar_files(tar_file_path, extract_dir, n_jobs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
