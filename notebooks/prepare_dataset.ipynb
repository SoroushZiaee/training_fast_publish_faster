{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610cbbbb-03f8-4e77-b16c-66e94326d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffcv.loader import Loader, OrderOption\n",
    "from ffcv.transforms import (\n",
    "    ToTensor,\n",
    "    ToDevice,\n",
    "    Squeeze,\n",
    "    NormalizeImage,\n",
    "    RandomHorizontalFlip,\n",
    "    ToTorchImage,\n",
    ")\n",
    "from ffcv.fields.rgb_image import (\n",
    "    CenterCropRGBImageDecoder,\n",
    "    RandomResizedCropRGBImageDecoder,\n",
    "ResizedCropRGBImageDecoder\n",
    ")\n",
    "from ffcv.fields.basics import IntDecoder, FloatDecoder\n",
    "\n",
    "import torch as ch\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9faaf17-337c-4153-8a31-bcf311e7ee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: no ordering seed was specified with distributed=True. Setting seed to 0 to match PyTorch distributed sampler.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Default process group has not been initialized, please make sure to call init_process_group.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_162972/1791091076.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRANDOM\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdistributed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mOrderOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUASI_RANDOM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m loader = Loader(\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/6067616/soroush1/training_fast_publish_faster/.venv/lib/python3.9/site-packages/ffcv/loader/loader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fname, batch_size, num_workers, os_cache, order, distributed, seed, indices, pipelines, custom_fields, drop_last, batches_ahead, recompile)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 self.reader)\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraversal_order\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTraversalOrder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mORDER_MAP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mmemory_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/6067616/soroush1/training_fast_publish_faster/.venv/lib/python3.9/site-packages/ffcv/traversal_order/random.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             self.sampler = DistributedSampler(self.indices,\n\u001b[0m\u001b[1;32m     15\u001b[0m                                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                               \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/6067616/soroush1/training_fast_publish_faster/.venv/lib/python3.9/site-packages/torch/utils/data/distributed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, num_replicas, rank, shuffle, seed, drop_last)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Requires distributed package to be available\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mnum_replicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_world_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/6067616/soroush1/training_fast_publish_faster/.venv/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36mget_world_size\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_get_group_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/6067616/soroush1/training_fast_publish_faster/.venv/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36m_get_group_size\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \"\"\"\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mGroupMember\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWORLD\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mdefault_pg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_pg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/6067616/soroush1/training_fast_publish_faster/.venv/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36m_get_default_group\u001b[0;34m()\u001b[0m\n\u001b[1;32m    427\u001b[0m     \"\"\"\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    430\u001b[0m             \u001b[0;34m\"Default process group has not been initialized, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;34m\"please make sure to call init_process_group.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Default process group has not been initialized, please make sure to call init_process_group."
     ]
    }
   ],
   "source": [
    "train_dataset = \"/home/soroush1/projects/def-kohitij/soroush1/training_fast_publish_faster/data/imagenet_train_256.ffcv\"\n",
    "num_workers = 1\n",
    "batch_size = 512\n",
    "distributed = 1\n",
    "in_memory = 1\n",
    "this_device = \"cuda:0\"\n",
    "IMAGENET_MEAN = np.array([0.485, 0.456, 0.406]) * 255\n",
    "IMAGENET_STD = np.array([0.229, 0.224, 0.225]) * 255\n",
    "DEFAULT_CROP_RATIO = 224 / 256\n",
    "\n",
    "res = 256\n",
    "\n",
    "decoder = RandomResizedCropRGBImageDecoder((res, res))\n",
    "image_pipeline = [\n",
    "    decoder,\n",
    "    RandomHorizontalFlip(),\n",
    "    ToTensor(),\n",
    "    ToDevice(ch.device(this_device), non_blocking=True),\n",
    "    ToTorchImage(),\n",
    "    NormalizeImage(IMAGENET_MEAN, IMAGENET_STD, np.float16),\n",
    "]\n",
    "\n",
    "label_pipeline = [\n",
    "    IntDecoder(),\n",
    "    ToTensor(),\n",
    "    Squeeze(),\n",
    "    ToDevice(ch.device(this_device), non_blocking=True),\n",
    "]\n",
    "\n",
    "order = OrderOption.RANDOM if distributed else OrderOption.QUASI_RANDOM\n",
    "\n",
    "loader = Loader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    order=order,\n",
    "    os_cache=in_memory,\n",
    "    drop_last=True,\n",
    "    pipelines={\"image\": image_pipeline, \"label\": label_pipeline},\n",
    "    distributed=distributed,\n",
    ")\n",
    "\n",
    "# First epoch includes compilation time\n",
    "for ims, labs in tqdm(loader):\n",
    "    pass\n",
    "# start_time = time.time()\n",
    "# for _ in range(100):\n",
    "#     for ims, labs in loader:\n",
    "#         pass\n",
    "print(f\"Shape: {ims.shape} | Time per epoch: {(time.time() - start_time) / 100:.5f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428c0b6-a84b-4341-aa2e-ce99f521ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = \"/home/soroush1/projects/def-kohitij/soroush1/training_fast_publish_faster/data/lamem_train_256.ffcv\"\n",
    "num_workers = 1\n",
    "batch_size = 256\n",
    "distributed = 0\n",
    "in_memory = 1\n",
    "this_device = \"cuda:0\"\n",
    "IMAGENET_MEAN = np.array([0.485, 0.456, 0.406]) * 255\n",
    "IMAGENET_STD = np.array([0.229, 0.224, 0.225]) * 255\n",
    "DEFAULT_CROP_RATIO = 224 / 256\n",
    "\n",
    "LAMEM_MEAN = np.load(\n",
    "            \"/home/soroush1/projects/def-kohitij/soroush1/pretrain-imagenet/datasets/LaMem/support_files/image_mean.npy\"\n",
    "        )\n",
    "\n",
    "res = 256\n",
    "\n",
    "decoder = ResizedCropRGBImageDecoder((res, res))\n",
    "image_pipeline = [\n",
    "    decoder,\n",
    "    ToTensor(),\n",
    "    ToDevice(ch.device(this_device), non_blocking=True),\n",
    "    ToTorchImage(),\n",
    "    NormalizeImage(IMAGENET_MEAN, IMAGENET_STD, np.float16),\n",
    "]\n",
    "\n",
    "label_pipeline = [\n",
    "    FloatDecoder(),\n",
    "    ToTensor(),\n",
    "    Squeeze(),\n",
    "    ToDevice(ch.device(this_device), non_blocking=True),\n",
    "]\n",
    "\n",
    "order = OrderOption.RANDOM if distributed else OrderOption.QUASI_RANDOM\n",
    "\n",
    "loader = Loader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    order=order,\n",
    "    os_cache=in_memory,\n",
    "    drop_last=True,\n",
    "    pipelines={\"image\": image_pipeline, \"label\": label_pipeline},\n",
    "    distributed=distributed,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
