{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fae3aa0d-da24-41c2-8282-eefd03608384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as ch\n",
    "import torchvision as tv\n",
    "\n",
    "from ffcv.loader import Loader, OrderOption\n",
    "from ffcv.transforms import (\n",
    "    ToTensor,\n",
    "    ToDevice,\n",
    "    Squeeze,\n",
    "    NormalizeImage,\n",
    "    RandomHorizontalFlip,\n",
    "    ToTorchImage,\n",
    "    Convert\n",
    ")\n",
    "from ffcv.fields.rgb_image import (\n",
    "    CenterCropRGBImageDecoder,\n",
    "    RandomResizedCropRGBImageDecoder,\n",
    "    SimpleRGBImageDecoder\n",
    ")\n",
    "from ffcv.fields.basics import IntDecoder, FloatDecoder\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from ffcv.pipeline.operation import Operation, AllocationQuery\n",
    "from ffcv.pipeline.compiler import Compiler\n",
    "from abc import abstractmethod\n",
    "\n",
    "from typing import Callable, Tuple, Optional\n",
    "from ffcv.pipeline.state import State\n",
    "from dataclasses import replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4fe58724-3cd4-42b5-b55c-2ca5c8ecac17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([0.2441, 0.1323, 0.7990, 0.3364, 0.2475, 0.6902, 0.4146, 0.7908, 0.5983,\n",
      "        0.9590])\n",
      "tensor([117.6884, 117.9610, 118.1297, 118.2820, 118.4500, 118.5726, 118.7102,\n",
      "        118.8694, 118.9920, 119.0743])\n",
      "tensor([-117.4443, -117.8287, -117.3307, -117.9456, -118.2025, -117.8824,\n",
      "        -118.2956, -118.0786, -118.3937, -118.1153])\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 256, 256]), torch.Size([3, 256, 256]))"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = ch.load(\"/home/soroush1/projects/def-kohitij/soroush1/pretrain-imagenet/datasets/LaMem/support_files/image_mean_rgb.pt\")\n",
    "rnd_tensor = ch.rand(3, 256, 256)\n",
    "print(f\"{ch.equal(rnd_tensor, rnd_tensor)}\")\n",
    "\n",
    "print(f\"{rnd_tensor[0, :10, 0]}\")\n",
    "print(f\"{mean[0, :10, 0]}\")\n",
    "print(f\"{(rnd_tensor - mean)[0, :10, 0]}\")\n",
    "print(f\"{ch.equal(rnd_tensor, rnd_tensor - mean)}\")\n",
    "mean.size(), rnd_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "88547876-4a6f-4af2-bb2b-f7ce2333a606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 32, 32])\n",
      "tensor([-1.5850, -1.1977, -1.5490,  2.3488, -2.0080,  1.0427, -0.1712, -0.5773,\n",
      "        -1.4751, -1.9090])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create example tensors\n",
    "batch_size = 10\n",
    "channels = 3\n",
    "height = 32\n",
    "width = 32\n",
    "\n",
    "# Tensor of shape [batch, channels, h, w]\n",
    "tensor_a = torch.randn(batch_size, channels, height, width)\n",
    "\n",
    "# Tensor of shape [channels, h, w]\n",
    "tensor_b = torch.randn(channels, height, width)\n",
    "\n",
    "# Subtract tensor_b from tensor_a\n",
    "result = tensor_a - tensor_b\n",
    "\n",
    "print(result.shape)  # Should be [batch_size, channels, height, width]\n",
    "print(result[0, 0, :10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d092e-9a25-4961-86dd-88e4d9539e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_a.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fc38f871-597f-4e30-8252-c310fc545b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "tensor([-1.6084,  0.1366,  1.5696, -1.3446, -2.0777,  0.1969, -0.2545, -2.2963,\n",
      "         0.6162, -0.7772])\n"
     ]
    }
   ],
   "source": [
    "for i in range(tensor_a.shape[0]):\n",
    "\n",
    "    result = tensor_a[i] - tensor_b\n",
    "    print(result.shape)  # Should be [batch_size, channels, height, width]\n",
    "    print(result[0, :10, 0])\n",
    "    \n",
    "    if i == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "bedf5291-4673-4255-ad3e-99bab7fe431a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.uint8"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a23ad271-1d86-406e-8eb0-47d93929beee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNormalize(Operation):\n",
    "\n",
    "    def __init__(self, mean):\n",
    "        self.mean = mean.cpu().numpy() if isinstance(mean, torch.Tensor) else mean\n",
    "\n",
    "    # Return the code to run this operation\n",
    "    # @abstractmethod\n",
    "    def generate_code(self) -> Callable:\n",
    "        parallel_range = Compiler.get_iterator()\n",
    "        mean = self.mean  # Capture mean as a local variable\n",
    "\n",
    "        def subtract_mean(images, dst):\n",
    "            for i in parallel_range(images.shape[0]):\n",
    "                # print(f\"Now here\")\n",
    "                # print(f\"{mean.shape = }\")\n",
    "                # print(f\"{images[i].size() = }\")\n",
    "                # print(f\"{dst[i].size() = }\")\n",
    "                dst[i] = images[i] - mean\n",
    "\n",
    "                if i == 0:\n",
    "                    print(f\"{(images[i] - mean)[0, :10, 0] = }\")\n",
    "\n",
    "            print(f\"{dst[0, 0, :10, 0] = }\")\n",
    "            return dst\n",
    "        subtract_mean.is_parallel = True\n",
    "        return subtract_mean\n",
    "\n",
    "    # @abstractmethod\n",
    "    def declare_state_and_memory(self, previous_state: State) -> Tuple[State, Optional[AllocationQuery]]:\n",
    "        print(f\"{previous_state.shape = }\")\n",
    "        c, h, w = previous_state.shape\n",
    "\n",
    "        new_shape = (c, h, w)\n",
    "\n",
    "        new_state = replace(previous_state, shape=new_shape)\n",
    "\n",
    "        mem_allocation = AllocationQuery(new_shape, previous_state.dtype)\n",
    "        \n",
    "        return (new_state, mem_allocation)\n",
    "\n",
    "class ToNumpy(Operation):\n",
    "    # Return the code to run this operation\n",
    "    # @abstractmethod\n",
    "    def generate_code(self) -> Callable:\n",
    "\n",
    "        def to_numpy(images, dst):\n",
    "            # print(f\"{images.size() = }\")\n",
    "            images = images.detach().cpu().numpy()\n",
    "            images = np.transpose(images, (0, 2, 3, 1))\n",
    "            # print(f\"{images.dtype = }\")\n",
    "            # print(f\"{type(images) = }\")\n",
    "            # return np.transpose(images.detach().cpu().numpy(), (0, 2, 3, 1)) # [20, 3, 256, 256] -> [20, 256, 256, 3]\n",
    "            return images # [20, 3, 256, 256] -> [20, 256, 256, 3]\n",
    "            \n",
    "        return to_numpy\n",
    "\n",
    "    # @abstractmethod\n",
    "    def declare_state_and_memory(self, previous_state: State) -> Tuple[State, Optional[AllocationQuery]]:\n",
    "        c, h, w = previous_state.shape\n",
    "        new_shape = (h, w, c)\n",
    "    \n",
    "        # Everything in the state stays the same other than the shape\n",
    "        # States are immutable, so we have to edit them using the\n",
    "        # dataclasses.replace function\n",
    "        new_state = replace(previous_state, jit_mode=False, shape=new_shape, dtype=np.uint8)\n",
    "        print(f\"{new_state = }\")\n",
    "\n",
    "        # print(f\"{previous_state.dtype = }\")\n",
    "        # We need to allocate memory for the new images\n",
    "        # so below, we ask for a memory allocation whose width and height is\n",
    "        # half the original image, with the same type\n",
    "        # (shape=(,)) of the same type as the image data\n",
    "        mem_allocation = AllocationQuery(new_shape, np.uint8)\n",
    "        return (new_state, mem_allocation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b871abd5-6a3b-4d7e-97cc-48427ade44a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything is loaded completely\n",
      "previous_state.shape = (3, 256, 256)\n",
      "previous_state.shape = (3, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(images[i] - mean)[0, :10, 0] = tensor([13.3116,  8.0390,  5.8703,  5.7180, 10.5500,  9.4274,  8.2898,  5.1306,\n",
      "         4.0080,  4.9257])\n",
      "dst[0, 0, :10, 0] = tensor([13,  8,  5,  5, 10,  9,  8,  5,  4,  4], dtype=torch.uint8)\n",
      "0: labs = tensor([0.8043, 0.7907, 0.8205, 0.8684, 0.8667, 0.9211, 0.9111, 0.5556, 0.7234,\n",
      "        0.5429, 0.7500, 0.8333, 0.9070, 0.6875, 0.9070, 0.8000, 0.6667, 0.6122,\n",
      "        0.5385, 0.8140], device='cuda:0', dtype=torch.float64)\n",
      "type(ims) = <class 'torch.Tensor'>\n",
      "ims[0, 0, :10, 0] = tensor([13.,  8.,  5.,  5., 10.,  9.,  8.,  5.,  4.,  4.], device='cuda:0',\n",
      "       dtype=torch.float16)\n",
      "0: ims.size() = torch.Size([20, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ims.float().mean() = tensor(123.5779, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:01,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(images[i] - mean)[0, :10, 0] = tensor([137.3116, 136.0390, 134.8703, 132.7180, 131.5500, 130.4274, 130.2898,\n",
      "        129.1306, 129.0080, 128.9257])\n",
      "dst[0, 0, :10, 0] = tensor([137, 136, 134, 132, 131, 130, 130, 129, 129, 128], dtype=torch.uint8)\n",
      "1: labs = tensor([0.6905, 0.7000, 0.7619, 0.8667, 0.6944, 0.8750, 0.6429, 0.8049, 0.7949,\n",
      "        0.5581, 0.7805, 0.8095, 0.9091, 0.7353, 0.6053, 0.7447, 0.8286, 0.6591,\n",
      "        0.5000, 0.6000], device='cuda:0', dtype=torch.float64)\n",
      "type(ims) = <class 'torch.Tensor'>\n",
      "ims[0, 0, :10, 0] = tensor([137., 136., 134., 132., 131., 130., 130., 129., 129., 128.],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "1: ims.size() = torch.Size([20, 3, 256, 256])\n",
      "1: ims.float().mean() = tensor(141.2969, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:02,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(images[i] - mean)[0, :10, 0] = tensor([-111.6884, -111.9610, -112.1297, -112.2820, -112.4500, -112.5726,\n",
      "        -112.7102, -112.8694, -112.9920, -113.0743])\n",
      "dst[0, 0, :10, 0] = tensor([145, 145, 144, 144, 144, 144, 144, 144, 144, 143], dtype=torch.uint8)\n",
      "2: labs = tensor([0.7500, 0.8095, 0.8718, 0.7273, 0.7568, 0.8621, 0.5000, 0.8723, 0.7442,\n",
      "        0.4000, 0.8696, 0.5294, 0.7429, 0.8108, 0.6977, 0.6364, 0.8235, 0.9730,\n",
      "        0.6512, 0.7561], device='cuda:0', dtype=torch.float64)\n",
      "type(ims) = <class 'torch.Tensor'>\n",
      "ims[0, 0, :10, 0] = tensor([145., 145., 144., 144., 144., 144., 144., 144., 144., 143.],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "2: ims.size() = torch.Size([20, 3, 256, 256])\n",
      "2: ims.float().mean() = tensor(129.6190, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:02,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(images[i] - mean)[0, :10, 0] = tensor([-41.6884, -43.9610, -46.1297, -49.2820, -50.4500, -50.5726, -47.7102,\n",
      "        -46.8694, -44.9920, -45.0743])\n",
      "dst[0, 0, :10, 0] = tensor([215, 213, 210, 207, 206, 206, 209, 210, 212, 211], dtype=torch.uint8)\n",
      "3: labs = tensor([0.7273, 0.7838, 0.5938, 0.8108, 0.5122, 0.7818, 0.6857, 0.8750, 0.9677,\n",
      "        0.6410, 0.7895, 0.8462, 0.5208, 0.8718, 0.8108, 0.8421, 0.9750, 0.7317,\n",
      "        0.7500, 0.6585], device='cuda:0', dtype=torch.float64)\n",
      "type(ims) = <class 'torch.Tensor'>\n",
      "ims[0, 0, :10, 0] = tensor([215., 213., 210., 207., 206., 206., 209., 210., 212., 211.],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "3: ims.size() = torch.Size([20, 3, 256, 256])\n",
      "3: ims.float().mean() = tensor(131.2811, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:03,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(images[i] - mean)[0, :10, 0] = tensor([125.3116, 125.0390, 124.8703, 126.7180, 126.5500, 127.4274, 123.2898,\n",
      "        122.1306, 122.0080, 122.9257])\n",
      "dst[0, 0, :10, 0] = tensor([125, 125, 124, 126, 126, 127, 123, 122, 122, 122], dtype=torch.uint8)\n",
      "4: labs = tensor([0.8000, 0.6579, 0.8611, 0.6410, 0.8667, 0.5366, 0.8718, 0.8810, 0.5952,\n",
      "        0.8611, 0.8571, 0.9429, 0.8372, 0.8537, 0.7885, 0.6970, 0.8065, 0.5641,\n",
      "        0.7805, 0.7297], device='cuda:0', dtype=torch.float64)\n",
      "type(ims) = <class 'torch.Tensor'>\n",
      "ims[0, 0, :10, 0] = tensor([125., 125., 124., 126., 126., 127., 123., 122., 122., 122.],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "4: ims.size() = torch.Size([20, 3, 256, 256])\n",
      "4: ims.float().mean() = tensor(137.3767, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:03,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(images[i] - mean)[0, :10, 0] = tensor([ -4.6884,  -8.9610, -13.1297, -63.2820, -72.4500, -82.5726, -12.7102,\n",
      "        -28.8694, -47.9920,  -1.0743])\n",
      "dst[0, 0, :10, 0] = tensor([252, 248, 243, 193, 184, 174, 244, 228, 209, 255], dtype=torch.uint8)\n",
      "5: labs = tensor([0.9730, 0.6667, 0.7500, 0.6591, 0.7188, 0.8723, 0.9231, 0.7222, 0.5946,\n",
      "        0.7353, 0.6591, 0.7368, 0.4737, 0.6897, 0.9189, 0.7179, 0.5128, 0.8421,\n",
      "        0.7838, 0.7297], device='cuda:0', dtype=torch.float64)\n",
      "type(ims) = <class 'torch.Tensor'>\n",
      "ims[0, 0, :10, 0] = tensor([252., 248., 243., 193., 184., 174., 244., 228., 209., 255.],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "5: ims.size() = torch.Size([20, 3, 256, 256])\n",
      "5: ims.float().mean() = tensor(131.4686, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(images[i] - mean)[0, :10, 0] = tensor([2.3116, 2.0390, 1.8703, 2.7180, 2.5500, 3.4274, 4.2898, 4.1306, 4.0080,\n",
      "        4.9257])\n",
      "dst[0, 0, :10, 0] = tensor([2, 2, 1, 2, 2, 3, 4, 4, 4, 4], dtype=torch.uint8)\n",
      "(images[i] - mean)[0, :10, 0] = tensor([13.3116, 13.0390, 12.8703, 12.7180, 13.5500, 13.4274, 12.2898, 12.1306,\n",
      "        12.0080, 13.9257])\n",
      "dst[0, 0, :10, 0] = tensor([13, 13, 12, 12, 13, 13, 12, 12, 12, 13], dtype=torch.uint8)\n",
      "(images[i] - mean)[0, :10, 0] = tensor([-101.6884, -100.9610,  -98.1297,  -95.2820,  -90.4500,  -88.5726,\n",
      "         -86.7102,  -85.8694,  -86.9920,  -88.0743])\n",
      "dst[0, 0, :10, 0] = tensor([155, 156, 158, 161, 166, 168, 170, 171, 170, 168], dtype=torch.uint8)\n",
      "(images[i] - mean)[0, :10, 0] = tensor([17.3116, 17.0390, 19.8703, 16.7180, 13.5500, 10.4274,  8.2898, -2.8694,\n",
      "        -4.9920, -3.0743])\n",
      "dst[0, 0, :10, 0] = tensor([ 17,  17,  19,  16,  13,  10,   8, 254, 252, 253], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(\"everything is loaded completely\")\n",
    "\n",
    "train_dataset = \"/home/soroush1/projects/def-kohitij/soroush1/training_fast_publish_faster/data/lamem_train_256.ffcv\"\n",
    "num_workers = 1\n",
    "batch_size = 20\n",
    "distributed = 0\n",
    "in_memory = True\n",
    "this_device = \"cuda:0\"\n",
    "\n",
    "res = 256\n",
    "ratio = 256 / 256\n",
    "\n",
    "LAMEM_MEAN = ch.load(\"/home/soroush1/projects/def-kohitij/soroush1/pretrain-imagenet/datasets/LaMem/support_files/image_mean_rgb.pt\")\n",
    "normalize = CustomNormalize(LAMEM_MEAN)\n",
    "convert_to_numpy = ToNumpy()\n",
    "\n",
    "center_crop_decoder = CenterCropRGBImageDecoder((256, 256), ratio)\n",
    "random_resize_crop_decoder = RandomResizedCropRGBImageDecoder((res, res))\n",
    "\n",
    "image_pipeline = [\n",
    "    center_crop_decoder,\n",
    "    ToTensor(),\n",
    "    ToTorchImage(),\n",
    "    # random_resize_crop_decoder,\n",
    "    normalize,\n",
    "    ToDevice(ch.device(this_device), non_blocking=True),\n",
    "    Convert(ch.float16),\n",
    "]\n",
    "\n",
    "label_pipeline = [\n",
    "    FloatDecoder(),\n",
    "    ToTensor(),\n",
    "    Squeeze(),\n",
    "    ToDevice(ch.device(this_device), non_blocking=True),\n",
    "]\n",
    "\n",
    "order = OrderOption.RANDOM if distributed else OrderOption.QUASI_RANDOM\n",
    "\n",
    "loader = Loader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    order=order,\n",
    "    os_cache=in_memory,\n",
    "    drop_last=True,\n",
    "    pipelines={\"image\": image_pipeline, \"label\": label_pipeline},\n",
    "    distributed=distributed,\n",
    ")\n",
    "\n",
    "for i, (ims, labs) in tqdm(enumerate(loader)):\n",
    "    print(f\"{i}: {labs = }\")\n",
    "    print(f\"{type(ims) = }\")\n",
    "    if isinstance(ims, np.ndarray):\n",
    "        print(f\"{i}: {ims.shape = }\")\n",
    "        print(f\"{i}: {ims.dtype = }\")\n",
    "\n",
    "    else:\n",
    "        print(f\"{ims[0, 0, :10, 0] = }\")\n",
    "        print(f\"{i}: {ims.size() = }\")\n",
    "        print(f\"{i}: {ims.float().mean() = }\")\n",
    "\n",
    "    # with autocast():\n",
    "    #     clf, reg = multi_head_model(ims)\n",
    "\n",
    "    # print(f\"{clf.size() = }\")\n",
    "    # print(f\"{reg.size() = }\")\n",
    "\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8514d244-1697-4092-bbf3-34b479a38c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_a = [0.5078, 0.5435, 0.5146, 0.5420, 0.5796, 0.5396, 0.5259, 0.5244, 0.5205,\n",
    "        0.5269, 0.5225, 0.5605, 0.5132, 0.5312, 0.5479, 0.5444, 0.5630, 0.5718,\n",
    "        0.5254, 0.5283, 0.5317, 0.5308, 0.5298, 0.5435, 0.5234, 0.5557, 0.5181,\n",
    "        0.5381, 0.5352, 0.5322, 0.5293, 0.6719, 0.5234, 0.6313, 0.5107, 0.5220,\n",
    "        0.5229, 0.5352, 0.5439, 0.6162, 0.5483, 0.5200, 0.5254, 0.5815, 0.5342,\n",
    "        0.5337, 0.5049, 0.5293, 0.5430, 0.5366, 0.5352, 0.5459, 0.5405, 0.5190,\n",
    "        0.5332, 0.5488, 0.5312, 0.5220, 0.5278, 0.5229, 0.5273, 0.5264, 0.5542,\n",
    "        0.4927, 0.5532, 0.5386, 0.5283, 0.5166, 0.5371, 0.5259, 0.5322, 0.5366,\n",
    "        0.5381, 0.5132, 0.5278, 0.5317, 0.5430, 0.5361, 0.5366, 0.4675, 0.5913,\n",
    "        0.6084, 0.4988, 0.5391, 0.5356, 0.5200, 0.5361, 0.5273, 0.5225, 0.5361,\n",
    "        0.5015, 0.5176, 0.5327, 0.5078, 0.5293, 0.5225, 0.5186, 0.5312, 0.5312,\n",
    "        0.4829, 0.5254, 0.5483, 0.5400, 0.5298, 0.5327, 0.5400, 0.5435, 0.5220,\n",
    "        0.5273, 0.5244, 0.5195, 0.5664, 0.5405, 0.5742, 0.5430, 0.5376, 0.5244,\n",
    "        0.5649, 0.5718, 0.5420, 0.5278, 0.5317, 0.5234, 0.5293, 0.5210, 0.5308,\n",
    "        0.5303, 0.5347, 0.5425, 0.5234, 0.5215, 0.5317, 0.5195, 0.5137, 0.5220,\n",
    "        0.5112, 0.5210, 0.5166, 0.5015, 0.5503, 0.5298, 0.5112, 0.5283, 0.5337,\n",
    "        0.5439, 0.5117, 0.5269, 0.5293, 0.5059, 0.5571, 0.5181, 0.5464, 0.4893,\n",
    "        0.5391, 0.5557, 0.5205, 0.5366, 0.5059, 0.5137, 0.5361, 0.5264, 0.5352,\n",
    "        0.5391, 0.5361, 0.5361, 0.4890, 0.5327, 0.6304, 0.5425, 0.5269, 0.5444,\n",
    "        0.5371, 0.5327, 0.5283, 0.5371, 0.5166, 0.4783, 0.5513, 0.5176, 0.5391,\n",
    "        0.5288, 0.5322, 0.5273, 0.5522, 0.5415, 0.5854, 0.5264, 0.5298, 0.5391,\n",
    "        0.5112, 0.5391, 0.5317, 0.5386, 0.5449, 0.5522, 0.5483, 0.5371, 0.5283,\n",
    "        0.5200, 0.5371, 0.5122, 0.6016, 0.5273, 0.5210, 0.5278, 0.5244, 0.5449,\n",
    "        0.5474, 0.5283, 0.6738, 0.5234, 0.5864, 0.6055, 0.5181, 0.5464, 0.5942,\n",
    "        0.5688, 0.5278, 0.6743, 0.6499, 0.5288, 0.5205, 0.5098, 0.5356, 0.5254,\n",
    "        0.5347, 0.4988, 0.5303, 0.5151, 0.4995, 0.5186, 0.5483, 0.5503, 0.5103,\n",
    "        0.5439, 0.5210, 0.5352, 0.5430, 0.5244, 0.5361, 0.5239, 0.5503, 0.5283,\n",
    "        0.5337, 0.5464, 0.5273, 0.5278, 0.5420, 0.5386, 0.5190, 0.5400, 0.5215,\n",
    "        0.4338, 0.5518, 0.5376, 0.5029, 0.5249, 0.5229, 0.5195, 0.5288, 0.5044,\n",
    "        0.5166, 0.5464, 0.5234, 0.5269, 0.5142, 0.5073, 0.4878, 0.5054, 0.5254,\n",
    "        0.5273, 0.5264, 0.5127, 0.5371, 0.5532, 0.5308, 0.5518, 0.5200, 0.5205,\n",
    "        0.4954, 0.5308, 0.5386, 0.5156, 0.5693, 0.5386, 0.5347, 0.5366, 0.5151,\n",
    "        0.5444, 0.8726, 0.5308, 0.4556, 0.5273, 0.5254, 0.5078, 0.5327, 0.5239,\n",
    "        0.5503, 0.5317, 0.5278, 0.5254, 0.5615, 0.5317, 0.4978, 0.5200, 0.5342,\n",
    "        0.5312, 0.5283, 0.5767, 0.5205, 0.5137, 0.5254, 0.5420, 0.5288, 0.6333,\n",
    "        0.5430, 0.5508, 0.5508, 0.5186, 0.5273, 0.5278, 0.5205, 0.5439, 0.5405,\n",
    "        0.5361, 0.5186, 0.5762, 0.5415, 0.5332, 0.5278, 0.4819, 0.5522, 0.5098,\n",
    "        0.5366, 0.5269, 0.5063, 0.5405, 0.5273, 0.5239, 0.5220, 0.5254, 0.5464,\n",
    "        0.5420, 0.5396, 0.5015, 0.5562, 0.5386, 0.5522, 0.5835, 0.5410, 0.5005,\n",
    "        0.5444, 0.5107, 0.5142, 0.5249, 0.4648, 0.5171, 0.5327, 0.5132, 0.5347,\n",
    "        0.5210, 0.5410, 0.5327, 0.4978, 0.5400, 0.5649, 0.5742, 0.5415, 0.5142,\n",
    "        0.5342, 0.5312, 0.5508, 0.5625, 0.5210, 0.5342, 0.5444, 0.5190, 0.5093,\n",
    "        0.5068, 0.5425, 0.5234, 0.4924, 0.5151, 0.5327, 0.4983, 0.5361, 0.5391,\n",
    "        0.5122, 0.5117, 0.5488, 0.5376, 0.5366, 0.5425, 0.5244, 0.5186, 0.5239,\n",
    "        0.5405, 0.5415, 0.5024, 0.5317, 0.5288, 0.5342, 0.5171, 0.5327, 0.5146,\n",
    "        0.4861, 0.5210, 0.5884, 0.5757, 0.5444, 0.5356, 0.5098, 0.5283, 0.5278,\n",
    "        0.5312, 0.5474, 0.5332, 0.5420, 0.6528, 0.5405, 0.5171, 0.5386, 0.5303,\n",
    "        0.5200, 0.5410, 0.4727, 0.4993, 0.5381, 0.5288, 0.5200, 0.5298, 0.5806,\n",
    "        0.5356, 0.5479, 0.4321, 0.5479, 0.5381, 0.5952, 0.5684, 0.5312, 0.5229,\n",
    "        0.5225, 0.5410, 0.5308, 0.5322, 0.5454, 0.5225, 0.5444, 0.5420, 0.5215,\n",
    "        0.5854, 0.5273, 0.5371, 0.4932, 0.5205, 0.5234, 0.5312, 0.5283, 0.5322,\n",
    "        0.5132, 0.5376, 0.5308, 0.5244, 0.5220, 0.5332, 0.5439, 0.5044, 0.5356,\n",
    "        0.5347, 0.5347, 0.5312, 0.5244, 0.5176, 0.5386, 0.5103, 0.5029, 0.5376,\n",
    "        0.4495, 0.5503, 0.5522, 0.5254, 0.5400, 0.5459, 0.4963, 0.5166, 0.5703,\n",
    "        0.5264, 0.5972, 0.5767, 0.5718, 0.5264, 0.5088, 0.4937, 0.5776, 0.5327,\n",
    "        0.5391, 0.5493, 0.5264, 0.5347, 0.5059, 0.5386, 0.5249, 0.5317, 0.4978,\n",
    "        0.5425, 0.5278, 0.5283, 0.4883, 0.5210, 0.5361, 0.5137, 0.5298]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a6905f2-c417-4118-961c-43b9e19ab61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_b = [0.5000, 0.8718, 0.9130, 0.6750, 0.7241, 0.9394, 0.5714, 0.7826, 0.8378,\n",
    "        0.4242, 0.9189, 0.9231, 0.6216, 0.9333, 0.9250, 0.7353, 0.6875, 0.8214,\n",
    "        0.8235, 0.5366, 0.6176, 0.3590, 0.7391, 0.7727, 0.8409, 0.8571, 0.8049,\n",
    "        0.7556, 0.8333, 0.9556, 0.6744, 0.7857, 0.9556, 0.6000, 0.6774, 0.8500,\n",
    "        0.7179, 0.7442, 0.9459, 0.7879, 0.9286, 0.5476, 0.7660, 0.8649, 0.7500,\n",
    "        0.5652, 0.6047, 0.9250, 0.8837, 0.8409, 0.8919, 0.9211, 0.8000, 0.7755,\n",
    "        0.7105, 0.5833, 0.7353, 0.7826, 0.7000, 0.8182, 0.7568, 0.6286, 0.7297,\n",
    "        0.8537, 0.7500, 0.7250, 0.8205, 0.8293, 0.7576, 0.4595, 0.6667, 0.7400,\n",
    "        0.6923, 0.9000, 0.8378, 0.9268, 0.7442, 0.7838, 0.7436, 0.8438, 0.7778,\n",
    "        0.8235, 0.5122, 0.6250, 0.7188, 0.8200, 0.7000, 0.7568, 0.6667, 0.8810,\n",
    "        0.7949, 0.8857, 0.6667, 0.8000, 0.5161, 0.7250, 0.6316, 0.6250, 0.4390,\n",
    "        0.7561, 0.7778, 0.9412, 0.8974, 0.5556, 0.9000, 0.5333, 0.8750, 0.8140,\n",
    "        0.4571, 0.6190, 0.7027, 0.8085, 0.7500, 0.6000, 0.9048, 0.7750, 0.8478,\n",
    "        0.8158, 0.8718, 0.8333, 0.5938, 0.7273, 0.8571, 0.7222, 0.4762, 0.9623,\n",
    "        0.7400, 0.5814, 0.8857, 0.7000, 0.7436, 0.6154, 0.7805, 0.7556, 0.7179,\n",
    "        0.8571, 0.8056, 0.8571, 0.6667, 0.6923, 0.8947, 0.6591, 0.7500, 0.8222,\n",
    "        0.8500, 0.7000, 0.7429, 0.7609, 0.6571, 0.7436, 0.7021, 0.5476, 0.9643,\n",
    "        0.7805, 0.7368, 0.8636, 0.7059, 0.7561, 0.9706, 0.6410, 0.5946, 0.7442,\n",
    "        0.8667, 0.7568, 0.7209, 0.6346, 0.8293, 0.8974, 0.7561, 0.8000, 0.7500,\n",
    "        0.8788, 0.5526, 0.9268, 0.6744, 0.6579, 0.8372, 0.9167, 0.8800, 0.6977,\n",
    "        0.7647, 0.8378, 0.8780, 0.6000, 0.5862, 0.7632, 0.8710, 0.7297, 0.5476,\n",
    "        0.7429, 0.8095, 0.4884, 0.5455, 0.7059, 0.7750, 0.5116, 0.7857, 0.8684,\n",
    "        0.8750, 0.7895, 0.5000, 0.8913, 0.8182, 0.6905, 0.8276, 0.8095, 0.7805,\n",
    "        0.5135, 0.6857, 0.7179, 0.6585, 0.9487, 0.9048, 0.8780, 0.8378, 0.7750,\n",
    "        0.9535, 0.6452, 0.8085, 0.9189, 0.5946, 0.7234, 0.7805, 0.8065, 0.7368,\n",
    "        0.4857, 0.8378, 0.6829, 0.9714, 0.8085, 0.7143, 0.6667, 0.9706, 0.8182,\n",
    "        0.5714, 0.9412, 0.8000, 0.8250, 0.7949, 0.7105, 0.8649, 0.5526, 0.8222,\n",
    "        0.9091, 0.8621, 0.7895, 0.6889, 0.8462, 0.9250, 0.6190, 0.7805, 0.3548,\n",
    "        0.6279, 0.7742, 0.6500, 0.6444, 0.7907, 0.8710, 0.8000, 0.7727, 0.7805,\n",
    "        0.8542, 0.5294, 0.8696, 0.6279, 0.7576, 0.9211, 0.8108, 0.8718, 0.9118,\n",
    "        0.6512, 0.7222, 0.8718, 0.6857, 0.5909, 0.7727, 0.9189, 0.9444, 0.7500,\n",
    "        0.9000, 0.6944, 0.7179, 0.7568, 0.9375, 0.9091, 0.8919, 0.8421, 0.5882,\n",
    "        0.8864, 0.9737, 0.6667, 0.8205, 0.6875, 0.9118, 0.8696, 0.8824, 0.7442,\n",
    "        0.8056, 0.7778, 0.9070, 0.9268, 0.7179, 0.8085, 0.4737, 0.8333, 0.7778,\n",
    "        0.5429, 0.7568, 0.9722, 0.8947, 0.6944, 0.8293, 0.8857, 0.6061, 0.7083,\n",
    "        0.8409, 0.7188, 0.8140, 0.8684, 0.7660, 0.8605, 0.7500, 0.8095, 0.6667,\n",
    "        0.7419, 0.8857, 0.7895, 0.8571, 0.9167, 0.7174, 0.6765, 0.8205, 0.7045,\n",
    "        0.7143, 0.7500, 0.8049, 0.8947, 0.7551, 0.7429, 0.9130, 0.8529, 0.4524,\n",
    "        0.7347, 0.9744, 0.8571, 0.7692, 0.9750, 0.7317, 0.8537, 0.6842, 0.4872,\n",
    "        0.7619, 0.8409, 0.7143, 0.6809, 0.7021, 0.8000, 0.6383, 0.4444, 0.8387,\n",
    "        0.6842, 0.9545, 0.7000, 0.8000, 0.4722, 0.7800, 0.7907, 0.8043, 0.7576,\n",
    "        0.8182, 0.5526, 0.8974, 0.6875, 0.8500, 0.7368, 0.6809, 0.8158, 0.6190,\n",
    "        0.6765, 0.8000, 0.9091, 0.7234, 0.7857, 0.8542, 0.5263, 0.7714, 0.7234,\n",
    "        0.7667, 0.7143, 0.5814, 0.5556, 0.4737, 0.9070, 0.6136, 0.9167, 0.6875,\n",
    "        0.7391, 0.6410, 1.0000, 0.8158, 0.6000, 0.6364, 0.9149, 0.8286, 0.8261,\n",
    "        0.7561, 0.8387, 0.6829, 0.6739, 0.7333, 0.7447, 0.5366, 0.8529, 0.6905,\n",
    "        0.7727, 0.8250, 0.6667, 0.8205, 0.7500, 0.8043, 0.5116, 0.8421, 0.8857,\n",
    "        0.7907, 0.8684, 0.6000, 0.8537, 0.8611, 0.7632, 0.8974, 0.8780, 0.6591,\n",
    "        0.5556, 0.8286, 0.8158, 0.7234, 0.8500, 0.8333, 0.7179, 0.8158, 0.7381,\n",
    "        0.6905, 0.7000, 0.6944, 0.5128, 0.8857, 0.7143, 0.8947, 0.6486, 0.7333,\n",
    "        0.8605, 0.8750, 0.8140, 0.7436, 0.6667, 0.7872, 0.8537, 0.6042, 0.8222,\n",
    "        0.8000, 0.7714, 0.8378, 0.6452, 0.9750, 0.6098, 0.6667, 0.8750, 0.7692,\n",
    "        0.8889, 0.9333, 0.8718, 0.8182, 0.5897, 0.6136, 0.7778, 0.5250, 0.6250,\n",
    "        0.7917, 0.7838, 0.8750, 0.7059, 0.4524, 0.7436, 0.6364, 0.7872, 0.8095,\n",
    "        0.6000, 0.5750, 0.6512, 0.8649, 0.8378, 0.8140, 0.8205, 0.5682, 0.8108,\n",
    "        0.8163, 0.8049, 0.7333, 0.8529, 0.6757, 0.9355, 0.7353, 1.0000, 0.6364,\n",
    "        0.4688, 0.9474, 0.5854, 0.8864, 0.9333, 0.6591, 0.8000, 0.7447]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b2daf5-7bb7-4c0e-b2ff-2439d631d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_a = ch.Tensor(tensor_a)\n",
    "tensor_b = ch.Tensor(tensor_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb1c4c83-877b-4c0d-b5fc-496fa210d3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f2d5b12-619e-47cc-b4bb-7e845a7e5237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(tensor_a, tensor_b).float().dtype"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
